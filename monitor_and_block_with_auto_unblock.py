import os
import glob
import time
import shutil
from scapy.all import rdpcap, IP
import pandas as pd
import numpy as np
import joblib
import subprocess
import socket

# === åˆå§‹åŒ–è³‡æ–™å¤¾ ===
os.makedirs("new_dataset/csv", exist_ok=True)
os.makedirs("processed", exist_ok=True)

# === è¼‰å…¥æ¨¡å‹èˆ‡æ¨™æº–åŒ–å™¨ ===
model = joblib.load("isolation_forest_model.joblib")
scaler = joblib.load("feature_scaler.joblib")

# === è¿½è¹¤å·²è™•ç†éçš„ pcap æª”æ¡ˆ ===
processed_set = set(os.listdir("processed"))

# === è‡ªå‹•è§£å°è¨­å®šï¼ˆç§’ï¼‰ ===
UNBLOCK_AFTER_SECONDS = 600  # 10 åˆ†é˜

def get_local_ip():
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        # å‘ Google DNS å»ºç«‹ä¸€æ¬¡é€£ç·šï¼Œåªç‚ºäº†å–å‡ºæœ¬æ©Ÿ IP
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
    finally:
        s.close()
    return ip

local_ip = get_local_ip()

def count_files(directory):
    return sum(1 for entry in os.scandir(directory) if entry.is_file())

def auto_unblock():
    blocked_path = "blocked_ips.txt"
    if not os.path.exists(blocked_path):
        return
    with open(blocked_path, "r") as f:
        lines = f.read().splitlines()

    remaining = []
    unblocked = []

    for line in lines:
        if " " not in line:
            continue
        ip, ts_str = line.split()
        try:
            ts = int(ts_str)
            if time.time() - ts >= UNBLOCK_AFTER_SECONDS:
                print(f"ğŸ”“ è‡ªå‹•è§£å° IP: {ip}")
                try:
                    subprocess.run(["sudo", "iptables", "-D", "INPUT", "-s", ip, "-j", "DROP"], check=True)
                    unblocked.append(ip)
                except subprocess.CalledProcessError:
                    print(f"âš ï¸ è§£å°å¤±æ•—: {ip}")
            else:
                remaining.append(line)
        except ValueError:
            continue

    with open(blocked_path, "w") as f:
        f.write("\n".join(remaining))

    if unblocked:
        print(f"âœ… è‡ªå‹•è§£å°å®Œæˆï¼Œå…±ç§»é™¤ {len(unblocked)} å€‹ IP")

def process_pcap(pcap_file):
    print(f"\nğŸ“¦ è™•ç†æª”æ¡ˆ: {pcap_file}")
    packets = rdpcap(pcap_file)
    data = []
    global_last_time = None
    last_seen_time = {}

    for i, pkt in enumerate(packets):
        if IP in pkt:
            t = pkt.time
            src_ip = pkt[IP].src
            dst_ip = pkt[IP].dst
            data.append({
                "timestamp": t,
                "src_ip": src_ip,
                "dst_ip": dst_ip
            })

    if not data:
        print("âš ï¸ ç„¡æœ‰æ•ˆå°åŒ…ï¼Œç•¥é")
        return

    df = pd.DataFrame(data)
    df["timestamp"] = pd.to_numeric(df["timestamp"], errors="coerce")
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="s", errors="coerce")
    df = df.dropna(subset=["timestamp", "src_ip", "dst_ip"])
    df = df.sort_values("timestamp").reset_index(drop=True)

    # æ–°å¢ timestamp_seconds æ¬„ä½ä¾›æ»‘å‹•è¨ˆç®—
    df["timestamp_seconds"] = df["timestamp"].astype(np.int64) // 10**9
    df["packet_count_5s"] = 0

    # æ»‘å‹•æ™‚é–“çª—å£è¨ˆç®— + èšåˆçµ±è¨ˆ
    stat_list = []

    for ip, group in df.groupby("src_ip"):
        times = group["timestamp_seconds"].values
        dst_ips = group["dst_ip"].values
        counts = np.zeros(len(times), dtype=int)
        left = 0
        for right in range(len(times)):
            while times[right] - times[left] > 5:
                left += 1
            counts[right] = right - left + 1

        max_pc = counts.max()
        mean_pc = counts.mean()
        std_pc = counts.std()
        unique_dst = len(set(dst_ips))

        stat_list.append({
            "src_ip": ip,
            "packet_count_5s_max": max_pc,
            "packet_count_5s_mean": mean_pc,
            "packet_count_5s_std": std_pc,
            "unique_dst_ip_count": unique_dst
        })

    stat_df = pd.DataFrame(stat_list)

    # åŠ ä¸Š log_src_ip_avg_freq
    ip_counts = df["src_ip"].value_counts()
    ip_min_time = df.groupby("src_ip")["timestamp"].min()
    ip_max_time = df.groupby("src_ip")["timestamp"].max()
    duration = (ip_max_time - ip_min_time).dt.total_seconds().replace(0, 1)
    log_freq = np.log1p(ip_counts / duration)
    stat_df["log_src_ip_avg_freq"] = stat_df["src_ip"].map(log_freq)

    # é¸æ“‡è¼¸å‡ºæ¬„ä½
    keep_cols = [
        "src_ip",
        "packet_count_5s_max",
        "packet_count_5s_mean",
        "packet_count_5s_std",
        "unique_dst_ip_count",
        "log_src_ip_avg_freq"
    ]
    stat_df = stat_df[keep_cols]


    file_num = count_files("new_dataset/csv")
    csv_path = f"new_dataset/csv/traffic_data{file_num}_new.csv"
    stat_df.to_csv(csv_path, index=False)
    print(f"âœ… CSV å·²å„²å­˜: {csv_path} ({len(stat_df)} ç­†)")

    return csv_path

def predict_and_block(csv_path):
    df = pd.read_csv(csv_path)
    df.fillna({
        "packet_count_5s_max": 0,
        "packet_count_5s_mean": 0,
        "packet_count_5s_std": 0,
        "unique_dst_ip_count": 0,
        "log_src_ip_avg_freq": 0
    }, inplace=True)

    features = [
        "packet_count_5s_max",
        "packet_count_5s_mean",
        "packet_count_5s_std",
        "unique_dst_ip_count",
        "log_src_ip_avg_freq"
    ]

    X = scaler.transform(df[features])
    df["prediction"] = model.predict(X)
    df["anomaly"] = df["prediction"].apply(lambda x: 1 if x == -1 else 0)

    abnormal_df = df[df["anomaly"] == 1]
    ip_counts = abnormal_df["src_ip"].value_counts()
    to_block_ips = ip_counts.index.tolist()

    print(f"ğŸš¨ ç¬¦åˆå°é–é–€æª»çš„ IP æ•¸ï¼š{len(to_block_ips)}")

    blocked_path = "blocked_ips.txt"
    already_blocked = set()
    if os.path.exists(blocked_path):
        with open(blocked_path, "r") as f:
            already_blocked = {line.split()[0] for line in f.read().splitlines() if line.strip()}

    new_blocked = []
    with open(blocked_path, "a") as f:
        now = int(time.time())
        for ip in to_block_ips:
            if ip != local_ip and ip not in already_blocked:
                try:
                    subprocess.run(["sudo", "iptables", "-A", "INPUT", "-s", ip, "-j", "DROP"], check=True)
                    new_blocked.append(ip)
                    f.write(f"{ip} {now}\n")
                    print(f"âœ… å·²å°é–: {ip}")
                except subprocess.CalledProcessError:
                    print(f"âš ï¸ ç„¡æ³•å°é–: {ip}")
    # for ip in to_block_ips:
    #     print(f"âœ… å·²å°é–: {ip}")

    if new_blocked:
        print(f"âœ… å°é–å®Œæˆï¼Œå…±æ–°å¢ {len(new_blocked)} IP")

# === ä¸»è¿´åœˆï¼ˆæ¯ 30 ç§’æƒææ–°å°åŒ…ï¼‰ ===
print("ğŸ›¡ï¸ é–‹å§‹æŒçºŒç›£æ§å°åŒ…ä¸¦å°é–ç•°å¸¸ IP...\n")
while True:
    auto_unblock()
    pcap_files = sorted(glob.glob("new_dataset/*.pcap"))
    new_files = [f for f in pcap_files if os.path.basename(f) not in processed_set]

    for pcap in new_files:
        csv_path = process_pcap(pcap)
        if csv_path:
            predict_and_block(csv_path)
            shutil.move(pcap, os.path.join("processed", os.path.basename(pcap)))
            processed_set.add(os.path.basename(pcap))

    break
    time.sleep(30)
